{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a96dd54",
   "metadata": {},
   "source": [
    "# Inspection du dataset\n",
    "Affichage du CSV sous forme de DataFrame + tailles des DataLoaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4243f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from data.dataset import create_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a3234a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>non_seg</th>\n",
       "      <th>seg</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIX034925</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AIX043024</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AIX055881</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALF032718</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ALF032721</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALF032741</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ALF032746</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALF035277</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ALF035285</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALF035290</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>/data/Downloads/Data_Projet_Complet/Data_Proje...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    image_id                                            non_seg  \\\n",
       "0  AIX034925  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "1  AIX043024  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "2  AIX055881  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "3  ALF032718  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "4  ALF032721  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "5  ALF032741  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "6  ALF032746  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "7  ALF035277  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "8  ALF035285  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "9  ALF035290  /data/Downloads/Data_Projet_Complet/Data_Proje...   \n",
       "\n",
       "                                                 seg  label  \n",
       "0  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "1  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "2  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "3  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "4  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "5  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "6  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "7  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "8  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  \n",
       "9  /data/Downloads/Data_Projet_Complet/Data_Proje...    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paramètres\n",
    "CSV_FILE = \"../data/raw/prepared_dataset.csv\"\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Afficher le DataFrame (10 premières lignes)\n",
    "df = pd.read_csv(CSV_FILE)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12e10b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 718 images\n",
      "Val set: 180 images\n"
     ]
    }
   ],
   "source": [
    "# Créer les dataloaders\n",
    "train_loader, val_loader = create_dataloaders(\n",
    "    csv_file=CSV_FILE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    train_split=0.8,\n",
    "    img_size=224,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "print(f\"Train set: {len(train_loader.dataset)} images\")\n",
    "print(f\"Val set: {len(val_loader.dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b746f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 718 images\n",
      "Val set: 180 images\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# Extraire les 10 premiers échantillons\n",
    "data = []\n",
    "for i, (img_non_seg, img_seg, label) in enumerate(itertools.islice(train_loader.dataset, 10)):\n",
    "    data.append({\n",
    "        'Sample': i,\n",
    "        'Label': label.item() if hasattr(label, 'item') else label,\n",
    "        'Non-Seg Shape': str(img_non_seg.shape),\n",
    "        'Seg Shape': str(img_seg.shape)\n",
    "    })\n",
    "\n",
    "# Créer et afficher le DataFrame\n",
    "samples_df = pd.DataFrame(data)\n",
    "samples_df\n",
    "\n",
    "print(f\"Train set: {len(train_loader.dataset)} images\")\n",
    "print(f\"Val set: {len(val_loader.dataset)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f31872a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sample</th>\n",
       "      <th>Label</th>\n",
       "      <th>Non-Seg Shape</th>\n",
       "      <th>Seg Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "      <td>torch.Size([3, 224, 224])</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sample  Label              Non-Seg Shape                  Seg Shape\n",
       "0       0    0.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "1       1    1.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "2       2    0.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "3       3    1.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "4       4    0.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "5       5    1.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "6       6    1.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "7       7    1.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "8       8    1.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])\n",
       "9       9    0.0  torch.Size([3, 224, 224])  torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "\n",
    "# Extraire les 10 premiers échantillons\n",
    "data = []\n",
    "for i, (img_non_seg, img_seg, label) in enumerate(itertools.islice(train_loader.dataset, 10)):\n",
    "    data.append({\n",
    "        'Sample': i,\n",
    "        'Label': label.item() if hasattr(label, 'item') else label,\n",
    "        'Non-Seg Shape': str(img_non_seg.shape),\n",
    "        'Seg Shape': str(img_seg.shape)\n",
    "    })\n",
    "\n",
    "# Créer et afficher le DataFrame\n",
    "samples_df = pd.DataFrame(data)\n",
    "samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f6aae05",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cytech/Ing3/DeepLearning/PROJET_DEEPL/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "\n",
    "# Import pour enregistrer les modèles CrossViT\n",
    "import models.crossvit\n",
    "\n",
    "from training.training import train_model_crossvit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7adb11ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/1 [Config A]\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TRAIN:   0%|          | 0/23 [00:00<?, ?it/s]/home/cytech/Ing3/DeepLearning/PROJET_DEEPL/.venv/lib/python3.10/site-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "TRAIN:   0%|          | 0/23 [01:40<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m dataloaders \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_loader, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m: val_loader}\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Test d'entraînement (1 epoch)\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m model, history \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model_crossvit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataloaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m     24\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m history\n",
      "File \u001b[0;32m~/Ing3/DeepLearning/PROJET_DEEPL/src/training/training.py:95\u001b[0m, in \u001b[0;36mtrain_model_crossvit\u001b[0;34m(model, dataloaders, criterion, optimizer, scheduler, config, device, num_epochs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# backward + optimize (seulement en train)\u001b[39;00m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mclip_grad_norm_(model\u001b[38;5;241m.\u001b[39mparameters(), \u001b[38;5;241m1.0\u001b[39m)\n\u001b[1;32m     97\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/Ing3/DeepLearning/PROJET_DEEPL/.venv/lib/python3.10/site-packages/torch/_tensor.py:625\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    616\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    617\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    618\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    623\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    624\u001b[0m     )\n\u001b[0;32m--> 625\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Ing3/DeepLearning/PROJET_DEEPL/.venv/lib/python3.10/site-packages/torch/autograd/__init__.py:354\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    351\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    353\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 354\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_tuple\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Ing3/DeepLearning/PROJET_DEEPL/.venv/lib/python3.10/site-packages/torch/autograd/graph.py:841\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    839\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    840\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 841\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    842\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    844\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    845\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Paramètres d'entraînement (test rapide)\n",
    "LABEL_COL = \"label\"\n",
    "num_classes = df[LABEL_COL].nunique()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = timm.create_model(\"crossvit_tiny_224\", pretrained=False, num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.1)\n",
    "dataloaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "# Test d'entraînement (1 epoch)\n",
    "model, history = train_model_crossvit(\n",
    "    model=model,\n",
    "    dataloaders=dataloaders,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    config=\"A\",\n",
    "    device=device,\n",
    "    num_epochs=1\n",
    ")\n",
    "\n",
    "history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
